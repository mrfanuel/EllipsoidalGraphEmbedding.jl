{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MatrixNetworks\n",
    "using Distributions\n",
    "using Gadfly\n",
    "using Clustering\n",
    "using BenchmarkTools, Compat\n",
    "using DelimitedFiles\n",
    "using SparseArrays\n",
    "using LinearAlgebra\n",
    "using SphericalGraphEmbedding\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"PolBlogs\"\n",
    "dataset = \"PowerEU\"\n",
    "dataset = \"Facebook\"\n",
    "dataset = \"PowerUS\"\n",
    "dataset = \"HEP\"\n",
    "#dataset = \"Internet\"\n",
    "# dataset = \"CondMat2003\"\n",
    "#dataset = \"Pokec\"\n",
    "\n",
    "# Initialization\n",
    "A = 0\n",
    "r = 0\n",
    "dim0 = 0\n",
    "N = 0\n",
    "\n",
    "# nb iterations projected power method\n",
    "n_it_PPM = 30000\n",
    "\n",
    "# relative objective variation\n",
    "t = 1e-8\n",
    "\n",
    "# nb of times vector partition is repeated\n",
    "n_it_vec_part = 10 \n",
    "\n",
    "# nb updates vec part\n",
    "n_updates = 50 \n",
    "\n",
    "# shape of embedding\n",
    "shape = \"Ellipsoidal\"\n",
    "\n",
    "# Loading data\n",
    "\n",
    "if dataset == \"PolBlogs\"\n",
    "\n",
    "    A0 = readdlm(\"data/PolBlogs/PolBlogsAdj.txt\")\n",
    "    lab = readdlm(\"data/PolBlogs/LabelsPolBlogs.txt\")\n",
    "\n",
    "    dim0 = size(A0)\n",
    "    A  = zeros(Int64 ,dim0[1],dim0[1])\n",
    "\n",
    "    for i = 1:dim0[1]\n",
    "        for j = 1:dim0[1]\n",
    "            A[i,j] = Int64(A0[i,j])\n",
    "        end\n",
    "    end\n",
    "    A = A+A'\n",
    "    A = sparse(A)\n",
    "\n",
    "    A,_ = largest_component(A)\n",
    "\n",
    "    A0 = 0\n",
    "    N = size(A,2)\n",
    "\n",
    "    # number of columns of initial guess\n",
    "    d0 = 20\n",
    "\n",
    "    dim_embed_spectral = 2\n",
    "\n",
    "    # number of centroids thrown in embedding\n",
    "    n_clusters = 100\n",
    "\n",
    "elseif dataset == \"PowerEU\"\n",
    "\n",
    "    list = readdlm(\"data/PowerEU/ElistPowerEU.txt\")\n",
    "    dim0 = size(list)\n",
    "\n",
    "    M_int = zeros(Int64,dim0[1],2)\n",
    "\n",
    "    for i = 1:dim0[1]\n",
    "        for j = 1:2\n",
    "            M_int[i,j] = Int64(list[i,j])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    N = maximum([maximum(M_int[:,1]),maximum(M_int[:,2])])\n",
    "\n",
    "    A0 = spzeros(N,N)\n",
    "    A0 = sparse(M_int[:,1],M_int[:,2],vec(ones(Int64,dim0[1],1)),N,N)\n",
    "    A0 = A0 + A0'\n",
    "    A,_ = largest_component(A0)\n",
    "    N = size(A,2)\n",
    "    \n",
    "    A0 = 0\n",
    "    M_int = 0\n",
    "\n",
    "    # number of columns of initial guess\n",
    "    d0 = 50\n",
    "\n",
    "    dim_embed_spectral = 50\n",
    "\n",
    "    # number of centroids thrown in embedding\n",
    "    n_clusters = 100\n",
    "\n",
    "\n",
    "elseif dataset == \"Facebook\"\n",
    "\n",
    "    list = readdlm(\"data/Facebook/facebook-gender_edges.txt\")\n",
    "    dim0 = size(list)\n",
    "\n",
    "    M_int = zeros(Int64,dim0[1],2)\n",
    "\n",
    "    for i = 1:dim0[1]\n",
    "        for j = 1:2\n",
    "            M_int[i,j] = Int64(list[i,j]) + 1 # here start at 0\n",
    "        end\n",
    "    end\n",
    "\n",
    "    N = maximum([maximum(M_int[:,1]),maximum(M_int[:,2])]) # here start at 0\n",
    "\n",
    "    A0 = spzeros(N,N)\n",
    "    A0 = sparse(M_int[:,1],M_int[:,2],vec(ones(Int64,dim0[1],1)),N,N)\n",
    "    A0 = A0 + A0'\n",
    "    A,_ = largest_component(A0)\n",
    "\n",
    "    A0 = 0\n",
    "    M_int = 0\n",
    "\n",
    "    # number of columns of initial guess\n",
    "    d0 = 50\n",
    "\n",
    "    dim_embed_spectral = 8\n",
    "\n",
    "    # number of centroids thrown in embedding\n",
    "    n_clusters = 100\n",
    "\n",
    "elseif dataset == \"PowerUS\"\n",
    "\n",
    "    list = readdlm(\"data/PowerUS/ElistPowerUS.txt\")\n",
    "    dim0 = size(list)\n",
    "\n",
    "    M_int = zeros(Int64,dim0[1],2)\n",
    "\n",
    "    for i = 1:dim0[1]\n",
    "        for j = 1:2\n",
    "            M_int[i,j] = Int64(list[i,j])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    N = maximum([maximum(M_int[:,1]),maximum(M_int[:,2])])\n",
    "\n",
    "    A0 = spzeros(N,N)\n",
    "    A0 = sparse(M_int[:,1],M_int[:,2],vec(ones(Int64,dim0[1],1)),N,N)\n",
    "    A0 = A0 + A0'\n",
    "    A,_ = largest_component(A0)\n",
    "\n",
    "    A0 = 0\n",
    "    M_int = 0\n",
    "\n",
    "    # number of columns of initial guess\n",
    "    d0 = 50\n",
    "\n",
    "    dim_embed_spectral = 80\n",
    "\n",
    "    # number of centroids thrown in embedding\n",
    "    n_clusters = 100\n",
    "\n",
    "elseif dataset == \"HEP\"\n",
    "\n",
    "    list = readdlm(\"data/HEP/hep-year_edges.txt\")\n",
    "    dim0 = size(list)\n",
    "\n",
    "    M_int = zeros(Int64,dim0[1],2)\n",
    "\n",
    "    for i = 1:dim0[1]\n",
    "        for j = 1:2\n",
    "            M_int[i,j] = Int64(list[i,j]) \n",
    "        end\n",
    "    end\n",
    "\n",
    "    N = maximum([maximum(M_int[:,1]),maximum(M_int[:,2])]) \n",
    "\n",
    "    A0 = spzeros(N,N)\n",
    "    A0 = sparse(M_int[:,1],M_int[:,2],vec(ones(Int64,dim0[1],1)),N,N)\n",
    "    A0 = A0 + A0'\n",
    "    A,_ = largest_component(A0)\n",
    "\n",
    "    A0 = 0\n",
    "    M_int = 0\n",
    "\n",
    "    # number of columns of initial guess\n",
    "    d0 = 50\n",
    "\n",
    "    dim_embed_spectral = 40\n",
    "\n",
    "\n",
    "    # number of centroids thrown in embedding\n",
    "    n_clusters = 100\n",
    "\n",
    "elseif dataset == \"Wikivote\"\n",
    "\n",
    "    list = readdlm(\"data/Wikivote/wiki-Vote.txt\")\n",
    "    dim0 = size(list)\n",
    "\n",
    "    M_int = zeros(Int64,dim0[1],2)\n",
    "\n",
    "    for i = 1:dim0[1]\n",
    "        for j = 1:2\n",
    "            M_int[i,j] = Int64(list[i,j]) \n",
    "        end\n",
    "    end\n",
    "\n",
    "    N = maximum([maximum(M_int[:,1]),maximum(M_int[:,2])]) \n",
    "\n",
    "    A0 = spzeros(N,N)\n",
    "    A0 = sparse(M_int[:,1],M_int[:,2],vec(ones(Int64,dim0[1],1)),N,N)\n",
    "    A0 = A0 + A0'\n",
    "    A,_ = largest_component(A0)\n",
    "\n",
    "    A0 = 0\n",
    "    M_int = 0\n",
    "\n",
    "    # number of columns of initial guess\n",
    "    d0 = 50\n",
    "\n",
    "    dim_embed_spectral = 3\n",
    "\n",
    "    # number of centroids thrown in embedding\n",
    "    n_clusters = 100\n",
    "\n",
    "elseif dataset == \"Internet\"\n",
    "\n",
    "    list = readdlm(\"data/Internet/InternetEList.txt\")\n",
    "    dim0 = size(list)\n",
    "\n",
    "    M_int = zeros(Int64,dim0[1],2)\n",
    "\n",
    "    for i = 1:dim0[1]\n",
    "        for j = 1:2\n",
    "            M_int[i,j] = Int64(list[i,j]) + 1 # index start from 0\n",
    "        end\n",
    "    end\n",
    "\n",
    "    N = maximum([maximum(M_int[:,1]),maximum(M_int[:,2])]) \n",
    "\n",
    "    A0 = spzeros(N,N)\n",
    "    A0 = sparse(M_int[:,1],M_int[:,2],vec(ones(Int64,dim0[1],1)),N,N)\n",
    "    A0 = A0 + A0'\n",
    "    A,_ = largest_component(A0)\n",
    "\n",
    "    A0 = 0\n",
    "    M_int = 0\n",
    "\n",
    "    # number of columns of initial guess\n",
    "    d0 = 50\n",
    "\n",
    "    dim_embed_spectral = 18\n",
    "\n",
    "    # number of centroids thrown in embedding\n",
    "    n_clusters = 100\n",
    "\n",
    "elseif dataset == \"CondMat2003\"\n",
    "\n",
    "    list = readdlm(\"data/CondMat2003/CondMat2003EList.txt\")\n",
    "    dim0 = size(list)\n",
    "\n",
    "    M_int = zeros(Int64,dim0[1],2)\n",
    "\n",
    "    for i = 1:dim0[1]\n",
    "        for j = 1:2\n",
    "            M_int[i,j] = Int64(list[i,j]) + 1 # index start from 0\n",
    "        end\n",
    "    end\n",
    "\n",
    "    N = maximum([maximum(M_int[:,1]),maximum(M_int[:,2])])\n",
    "\n",
    "    A0 = spzeros(N,N)\n",
    "    A0 = sparse(M_int[:,1],M_int[:,2],vec(ones(Int64,dim0[1],1)),N,N)\n",
    "    A0 = A0 + A0'\n",
    "    A,_ = largest_component(A0)\n",
    "\n",
    "    A0 = 0\n",
    "    p = 0\n",
    "    M_int = 0\n",
    "\n",
    "    # number of columns of initial guess\n",
    "    d0 = 50\n",
    "\n",
    "    dim_embed_spectral = 80\n",
    "\n",
    "    # number of centroids thrown in embedding\n",
    "    n_clusters = 100\n",
    "\n",
    "elseif dataset == \"Pokec\"\n",
    "\n",
    "    list = readdlm(\"data/Pokec/soc-pokec-relationships.txt\")\n",
    "    dim0 = size(list)\n",
    "\n",
    "    M_int = zeros(Int64,dim0[1],2)\n",
    "\n",
    "    for i = 1:dim0[1]\n",
    "        for j = 1:2\n",
    "            M_int[i,j] = Int64(list[i,j]) + 1 # index start from 0\n",
    "        end\n",
    "    end\n",
    "\n",
    "    N = maximum([maximum(M_int[:,1]),maximum(M_int[:,2])])\n",
    "\n",
    "    A0 = spzeros(N,N)\n",
    "    A0 = sparse(M_int[:,1],M_int[:,2],vec(ones(Int64,dim0[1],1)),N,N)\n",
    "    A0 = A0 + A0'\n",
    "    A,_ = largest_component(A0)\n",
    "\n",
    "    A0 = 0\n",
    "    M_int = 0\n",
    "\n",
    "    # number of columns of initial guess\n",
    "    d0 = 50\n",
    "    dim_embed_spectral = 50\n",
    "\n",
    "    # number of centroids thrown in embedding\n",
    "    n_clusters = 100\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------- Acc Projected Power Iteration -------\n",
      "The iteration has become stationary after 111 iterations\n",
      " 95.444524 seconds (3.39 k allocations: 10.174 GiB, 6.27% gc time)\n",
      " -------------- Clustering ------- \n",
      "dimension of embedding used for clustering: 50\n",
      "Number of updates: 37\n",
      "Number of communities: 11\n",
      "Modularity: 0.6201242829562491\n",
      " -------------------------------------------- \n",
      "The first 5 squared singular values divided by N : \n",
      "[0.527310896378853, 0.2491721352969269, 0.1603629710122631, 0.04196229216936058, 0.02108053602060397]\n",
      " -------------------------------------------- \n",
      "242.666619 seconds (21.95 M allocations: 26.686 GiB, 4.82% gc time)\n",
      "HEP\n"
     ]
    }
   ],
   "source": [
    "community = zeros(Int64,N,1)\n",
    "x_embed,community,singular =  @time sphere_embed_cluster(A, n_it_PPM, t, n_clusters, n_it_vec_part, n_updates, shape, d0)\n",
    "# run twice to get timings without compilation time\n",
    "println(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral embedding computed\n",
      "Number of updates: 21\n",
      "Number of communities: 28\n",
      "Modularity: 0.5303062192918795\n",
      "922.557853 seconds (21.27 M allocations: 549.647 GiB, 9.80% gc time)\n",
      "HEP\n"
     ]
    }
   ],
   "source": [
    "tol = 1e-06\n",
    "it_max = 1000\n",
    "# spectral embedding\n",
    "community = zeros(Int64,N,1)\n",
    "x_embed, community, eigenvalues = @time spectral_embed_cluster(A, it_max, tol, n_clusters, n_rep_vec_part, n_updates, dim_embed_spectral)\n",
    "println(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
