{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import louvain\n",
    "import time\n",
    "\n",
    "print(\"Construct the graph from the txt file (edgelist)\")\n",
    "\n",
    "# select below the network you want\n",
    "\n",
    "########################\n",
    "# Polblogs\n",
    "name = \"pol_blogs\"\n",
    "input = np.loadtxt(\"../data/PolBlogs/PolBlogsAdj.txt\", dtype='i', delimiter='\\t')\n",
    "dim = input.shape\n",
    "N = dim[0]\n",
    "\n",
    "g = ig.Graph()\n",
    "g.add_vertices(N)\n",
    "for i in range(0, N-1):\n",
    "    for j in range(0,N-1):\n",
    "        if input[i,j]==1:\n",
    "            g.add_edges([(i,j)])\n",
    "            \n",
    "ig.summary(g)\n",
    "########################\n",
    "# # Wikivote\n",
    "# name = \"wikivote\"\n",
    "# input = np.loadtxt(\"../data/Wikivote/wiki-Vote.txt\", dtype='i', delimiter='\\t')\n",
    "# dim = input.shape\n",
    "# g = ig.Graph()\n",
    "# N = input.max()\n",
    "# g.add_vertices(N)\n",
    "# for i in range(0, dim[0]):\n",
    "#     g.add_edges([(input[i,0]-1,input[i,1]-1)])\n",
    "#     #if np.mod(i,100)==0: \n",
    "#      #   print(i)\n",
    "# ig.summary(g)\n",
    "########################\n",
    "# PowerEU\n",
    "# name = \"power_eu\"\n",
    "# input = np.loadtxt(\"../data/PowerEU/ElistPowerEU.txt\", dtype='i', delimiter=' ')\n",
    "# dim = input.shape\n",
    "# N = input.max()\n",
    "# g = ig.Graph()\n",
    "# g.add_vertices(N)\n",
    "# for i in range(0, dim[0]):\n",
    "#     g.add_edges([(input[i,0]-1,input[i,1]-1)])\n",
    "# ig.summary(g)\n",
    "########################\n",
    "# CondMat2003\n",
    "# name = \"condmat2003\"\n",
    "# g = ig.Graph.Read_Ncol('../data/CondMat2003/CondMat2003EList.txt', directed=False)\n",
    "########################\n",
    "# # Internet\n",
    "# name = \"internet\"\n",
    "# g = ig.Graph.Read_Ncol('../data/Internet/InternetElist.txt', directed=False)\n",
    "########################\n",
    "# # PowerUS\n",
    "# name=\"power_us\"\n",
    "# input = np.loadtxt(\"../data/PowerUS/ElistPowerUS.txt\", dtype='i', delimiter=' ')\n",
    "# dim = input.shape\n",
    "# N = input.max()\n",
    "# g = ig.Graph()\n",
    "# g.add_vertices(N)\n",
    "# for i in range(0, dim[0]):\n",
    "#     g.add_edges([(input[i,0]-1,input[i,1]-1)])\n",
    "# ig.summary(g)\n",
    "########################\n",
    "# # Facebook\n",
    "# name = \"facebook\"\n",
    "# g = ig.Graph.Read_Ncol('../data/Facebook/facebook-gender_edges.txt', directed=False)\n",
    "########################\n",
    "# # Pokec\n",
    "# name=\"pokec\"\n",
    "# g = ig.Graph.Read_Ncol('../data/Pokec/soc-pokec-relationships.txt', directed=False)\n",
    "########################\n",
    "\n",
    "# selects largest connected component\n",
    "\n",
    "print(\"Largest connected component\")\n",
    "largest = g.clusters().giant();\n",
    "N = largest.vcount()\n",
    "ig.summary(largest)\n",
    "# save cc in txt\n",
    "ig.write(largest,filename=\"edge_lists/\"+name+\"_largest.txt\",format = \"edgelist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Louvain 1 times in C++\")\n",
    "start_time = time.time()\n",
    "\n",
    "part = louvain.find_partition(largest, louvain.ModularityVertexPartition);\n",
    "\n",
    "        \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(\"Modularity :\",part.modularity)\n",
    "print(\"Sizes of the groups:\", part.sizes())\n",
    "print(\"Nb of  groups:\", len(part.sizes()))\n",
    "\n",
    "# print(\"Running Louvain 10 times in C++\")\n",
    "# start_time = time.time()\n",
    "\n",
    "# m_best =0;\n",
    "# part_best = louvain.find_partition(largest, louvain.ModularityVertexPartition);\n",
    "\n",
    "\n",
    "# for n in range(10):\n",
    "#     part = louvain.find_partition(largest, louvain.ModularityVertexPartition);\n",
    "#     m = part.modularity;\n",
    "\n",
    "#     if m_best<m:\n",
    "#         m_best = m;\n",
    "#         part_best = part;\n",
    "        \n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# print(\"Modularity :\",part_best.modularity)\n",
    "# print(\"Sizes of the groups:\", part_best.sizes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node2Vec follows by k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec embedding with the original code \n",
    "# https://github.com/aditya-grover/node2vec\n",
    "# simply adapted to be compatible with python3\n",
    "\n",
    "if name==\"pol_blogs\":\n",
    "    start_time = time.time()\n",
    "    !python3 node2vec-master/src/main.py --dimensions 32 --input edge_lists/pol_blogs_largest.txt --output emb/output.txt\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "elif name==\"power_eu\":\n",
    "    start_time = time.time()\n",
    "    !python3 node2vec-master/src/main.py --dimensions 32 --input edge_lists/power_eu_largest.txt --output emb/output.txt\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "elif name==\"wikivote\":\n",
    "    start_time = time.time()\n",
    "    !python3 node2vec-master/src/main.py --dimensions 32 --input edge_lists/wikivote_largest.txt --output emb/output.txt\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "elif name==\"condmat2003\":\n",
    "    start_time = time.time()\n",
    "    !python3 node2vec-master/src/main.py --dimensions 32 --input edge_lists/condmat2003_largest.txt --output emb/output.txt\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "elif name==\"power_us\":\n",
    "    start_time = time.time()\n",
    "    !python3 node2vec-master/src/main.py --dimensions 32 --input edge_lists/power_us_largest.txt --output emb/output.txt\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "elif name==\"internet\": \n",
    "    start_time = time.time()\n",
    "    !python3 node2vec-master/src/main.py --dimensions 32 --input edge_lists/internet_largest.txt --output emb/output.txt\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "elif name==\"internet\": \n",
    "    start_time = time.time()\n",
    "    !python3 node2vec-master/src/main.py --dimensions 32 --input edge_lists/internet_largest.txt --output emb/output.txt\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "elif name==\"facebook\": \n",
    "    start_time = time.time()\n",
    "    !python3 node2vec-master/src/main.py --dimensions 32 --input edge_lists/facebook_largest.txt --output emb/output.txt\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "elif name==\"pokec\": \n",
    "    start_time = time.time()\n",
    "    !python3 node2vec-master/src/main.py --dimensions 32 --input edge_lists/pokec_largest.txt --output emb/output.txt\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time)) \n",
    "    \n",
    "print(\"Loading embedding vectors\")\n",
    "\n",
    "input = np.loadtxt(\"emb/output.txt\", skiprows=1) # row 1 contains nb of nodes and nb of edges\n",
    "id = input[:,0] # id of each node\n",
    "inv_perm = np.argsort(id)\n",
    "embed_vectors = input[inv_perm,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(embed_vectors)\n",
    "#print(pca.singular_values_)\n",
    "embedding = pca.transform(embed_vectors)\n",
    "\n",
    "max_nb_clusters = 50\n",
    "modularities = [] \n",
    "for k in range(1,max_nb_clusters+1):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0, n_init=\"auto\").fit(embed_vectors)\n",
    "    community = kmeans.labels_\n",
    "    mod_partition = largest.modularity(community)\n",
    "    modularities.append(mod_partition)\n",
    "\n",
    "modularities = np.array(modularities)\n",
    "\n",
    "print(\"nb communities %s \" % np.argmax(modularities))\n",
    "print(\"modularity %s \" % np.max(modularities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=embedding[:,0]\n",
    "# y=embedding[:,1]\n",
    "# z=embedding[:,2]\n",
    "# fig = plt.figure(figsize=(12, 12))\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# ax.scatter(x, y, z,c=community)\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
